{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\n\nimport numpy as np \nimport pandas as pd\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom torch import nn \nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error","metadata":{"id":"5241c671-48c9-4034-b113-4c285e33b51b","execution":{"iopub.status.busy":"2022-03-20T12:56:15.191625Z","iopub.execute_input":"2022-03-20T12:56:15.191934Z","iopub.status.idle":"2022-03-20T12:56:15.200753Z","shell.execute_reply.started":"2022-03-20T12:56:15.191901Z","shell.execute_reply":"2022-03-20T12:56:15.199396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport os\nSEED_VAL  = 1000\n# Set the seed value all over the place to make this reproducible.\ndef seed_all(SEED):\n  random.seed(SEED_VAL)\n  np.random.seed(SEED_VAL)\n  torch.manual_seed(SEED_VAL)\n  torch.cuda.manual_seed_all(SEED_VAL)\n  os.environ['PYTHONHASHSEED'] = str(SEED_VAL)\n  torch.backends.cudnn.deterministic = True\nseed_all(SEED_VAL)","metadata":{"id":"9bQJ-pUKInAd","execution":{"iopub.status.busy":"2022-03-20T12:56:15.219613Z","iopub.execute_input":"2022-03-20T12:56:15.22282Z","iopub.status.idle":"2022-03-20T12:56:15.241469Z","shell.execute_reply.started":"2022-03-20T12:56:15.222766Z","shell.execute_reply":"2022-03-20T12:56:15.239796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"https://storage.googleapis.com/umojahack2022/train.csv\")\ntest_df = pd.read_csv(\"https://storage.googleapis.com/umojahack2022/test.csv\")","metadata":{"id":"f162f6bb-0dfd-4310-a096-a584aee0f471","execution":{"iopub.status.busy":"2022-03-20T12:56:15.247873Z","iopub.execute_input":"2022-03-20T12:56:15.248633Z","iopub.status.idle":"2022-03-20T12:56:16.137625Z","shell.execute_reply.started":"2022-03-20T12:56:15.248583Z","shell.execute_reply":"2022-03-20T12:56:16.136735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.tail()","metadata":{"id":"wsGP-LGiMH5-","outputId":"7f00599f-a491-4407-dcc2-901bc4982f81","execution":{"iopub.status.busy":"2022-03-20T12:56:16.139211Z","iopub.execute_input":"2022-03-20T12:56:16.139514Z","iopub.status.idle":"2022-03-20T12:56:16.158145Z","shell.execute_reply.started":"2022-03-20T12:56:16.139455Z","shell.execute_reply":"2022-03-20T12:56:16.157052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each row in the dataset represents a k-mer (16 amino acid sequence within the toxin) and it has a signal column coming from the high-density peptide microarray experiment. The dataframe has the following columns :\n```\nID: Unique identifier for each row \nToxin_UniprotID: Identifier for a specific toxin sequence in the Uniprot Database\nKmer_Position_start: The start position in the toxin global sequence of the Kmer_Position_end: The end  position in the toxin global sequence a given k-mer \nAntivenom: Name of the antivenom tested in the high-density peptide microarray experiment\nToxin_Kmer: String of 16 amino acids (16-mer, K=16) from a given toxin sequence\nSignal: (target) The output of the experiment. A proxy for antivenom activity.\nGenus: Genus of snake the toxin stems from, e.g. Naja (cobra)\nSpecies: Species of snake the toxin originates from e.g. Naja nigricollis (Black-necked spitting cobra)\nProteinFam: Toxin protein family, e.g. three finger toxin (3FTx)\nProteinSubFam: Toxin sub-family, e.g. cytotoxin (a type of 3FTx)\nProteinSubSubFam: Toxin sub-sub-family, e.g. cytotoxin IA (a type of cytotoxin)\n```\n\nWe can use any of these colums to train our ML model.\n\nFor our model, we will use the `Antivenom` and the `Toxin_Kmer` and the `Kmer_Position_start` columns.","metadata":{"id":"fS-A-c-KMHnl"}},{"cell_type":"markdown","source":"We will first create our maps, which converts amino acids of the Toxin Kmer sequence and the Antivenom classes to numerical values","metadata":{"id":"eZ0ooJ5vLzxc"}},{"cell_type":"code","source":"def get_seq_column_map(train, test, col):\n    sequences = []\n    for seq in train[col]:\n        sequences.extend(list(seq))\n    for seq in test[col]:\n        sequences.extend(list(seq))\n    unique = np.unique(sequences)\n    return {k: v for k, v in zip(unique, range(len(unique)))}\n\ndef get_column_map(train, test, col):\n    sequences = []\n    unique_values = pd.concat([train[col], test[col]]).unique().tolist()\n    return {k: v for k, v in zip(unique_values, range(len(unique_values)))}","metadata":{"id":"5280d7c6-57df-4822-af33-e24ca6b13f2e","execution":{"iopub.status.busy":"2022-03-20T12:56:16.161243Z","iopub.execute_input":"2022-03-20T12:56:16.161893Z","iopub.status.idle":"2022-03-20T12:56:16.173174Z","shell.execute_reply.started":"2022-03-20T12:56:16.161846Z","shell.execute_reply":"2022-03-20T12:56:16.172103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"amino_acid_map = get_seq_column_map(train_df, test_df, \"Toxin_Kmer\")\nprint(\"unique amino acid map\",len(amino_acid_map))\n\nantivenom_map = get_column_map(train_df, test_df, \"Antivenom\")\nprint(\"unique Antivenom map\", len(antivenom_map))","metadata":{"id":"jTTjPAPN4b5c","outputId":"07e7c18d-05d0-4ef9-8262-41cc32ba7dbd","execution":{"iopub.status.busy":"2022-03-20T12:56:16.174948Z","iopub.execute_input":"2022-03-20T12:56:16.175309Z","iopub.status.idle":"2022-03-20T12:56:17.098724Z","shell.execute_reply.started":"2022-03-20T12:56:16.175263Z","shell.execute_reply":"2022-03-20T12:56:17.097696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will split the data into a training and a validation set","metadata":{"id":"YSDgPC4YNm1w"}},{"cell_type":"markdown","source":"We look at the GPU provided by Colab","metadata":{"id":"49jlxU1QN4s3"}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"device : {device}\")\ntorch.cuda.get_device_name()","metadata":{"tags":[],"id":"810517e6-008a-485c-8f6d-74db2cfb1770","outputId":"ce1bd98b-9bd6-46fc-bffa-66e96f0cac6b","execution":{"iopub.status.busy":"2022-03-20T12:56:17.100583Z","iopub.execute_input":"2022-03-20T12:56:17.101246Z","iopub.status.idle":"2022-03-20T12:56:17.112853Z","shell.execute_reply.started":"2022-03-20T12:56:17.101158Z","shell.execute_reply":"2022-03-20T12:56:17.111358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We convert our data into a torch `Dataset`.\nAll datasets that represent a map from keys to data samples should subclass\n`Dataset`. All subclasses should overwrite `__getitem__`, supporting fetching a data sample for a given key:","metadata":{"id":"y4HuvmEUODzZ"}},{"cell_type":"code","source":"class AntivenomChallengeDataSet(Dataset):\n    def __init__(\n        self,\n        amino_acid_map,\n        antivenom_map,\n        data,\n        is_train,\n        label_name=None,\n      ):\n        self.amino_acid_map = amino_acid_map\n        self.antivenom_map = antivenom_map\n        self.data = data\n        self.is_train = is_train\n        self.label_name = label_name\n\n    def __len__(self):\n        return len(self.data) \n\n    def __getitem__(self,idx):\n        row = self.data.iloc[idx]\n        kmer_seq = torch.as_tensor([self.amino_acid_map[e] for e in list(row[\"Toxin_Kmer\"])])\n        antivenom = torch.as_tensor(self.antivenom_map[row[\"Antivenom\"]])\n        position_start = torch.as_tensor(row[\"Kmer_Position_start\"])\n        position_end = torch.as_tensor(row[\"Kmer_Position_end\"])\n        \n        inputs = {\n            \"K_mer\": kmer_seq,\n            \"antivenom\": antivenom,\n            \"position_start\": position_start,\n            \"position_end\": position_end,\n        }\n\n        if self.is_train: \n            return inputs, torch.as_tensor([row[self.label_name]])\n        return inputs","metadata":{"id":"5c38ed84-d4a2-4045-99b6-3165e4b7ea76","execution":{"iopub.status.busy":"2022-03-20T12:56:17.115048Z","iopub.execute_input":"2022-03-20T12:56:17.115699Z","iopub.status.idle":"2022-03-20T12:56:17.127815Z","shell.execute_reply.started":"2022-03-20T12:56:17.115652Z","shell.execute_reply":"2022-03-20T12:56:17.126251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_dataset = AntivenomChallengeDataSet(\n    amino_acid_map=amino_acid_map,\n    antivenom_map=antivenom_map,\n    data=test_df,\n    is_train=False,\n)","metadata":{"id":"04ee359a-ab9f-422e-ae71-50685acd0c44","execution":{"iopub.status.busy":"2022-03-20T12:56:17.129599Z","iopub.execute_input":"2022-03-20T12:56:17.13082Z","iopub.status.idle":"2022-03-20T12:56:17.142283Z","shell.execute_reply.started":"2022-03-20T12:56:17.130771Z","shell.execute_reply":"2022-03-20T12:56:17.141269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 256\nnum_workers = 0\nshuffle = True\ndrop_last = False","metadata":{"id":"3cc84cdb-dfc7-4910-a83f-2d1a52ddd5e4","execution":{"iopub.status.busy":"2022-03-20T15:52:35.058252Z","iopub.execute_input":"2022-03-20T15:52:35.0586Z","iopub.status.idle":"2022-03-20T15:52:35.063664Z","shell.execute_reply.started":"2022-03-20T15:52:35.05857Z","shell.execute_reply":"2022-03-20T15:52:35.062468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we create our PyTorch data loaders. These combine a dataset and a sampler, and provide an iterable over the given dataset.","metadata":{"id":"sQ15jMHhO3zh"}},{"cell_type":"code","source":"test_data_loader= DataLoader(\n    dataset=test_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    drop_last=False,\n)","metadata":{"id":"c0e3ab3d-540b-4a84-ac68-61376aefb299","execution":{"iopub.status.busy":"2022-03-20T15:52:39.332414Z","iopub.execute_input":"2022-03-20T15:52:39.332767Z","iopub.status.idle":"2022-03-20T15:52:39.340609Z","shell.execute_reply.started":"2022-03-20T15:52:39.332705Z","shell.execute_reply":"2022-03-20T15:52:39.337378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define the model\nFor this example we will build an LSTM architeture. It is your task to come up with more performant architectures to improve the scores.","metadata":{"id":"4lXf0OdpP_zh"}},{"cell_type":"code","source":"class SimpleSeqModel(nn.Module):\n    def __init__(\n        self,\n        K_mer_emb_size,\n        K_mer_nunique,\n        antivenom_emb_size,\n        antivenom_unique,\n        max_Position_start,\n        Position_start_emb_size,\n    ): \n        super().__init__()\n        self.K_mer_emb_size = K_mer_emb_size        \n        self.K_mer_nunique = K_mer_nunique                \n        self.antivenom_emb_size = antivenom_emb_size  \n        self.antivenom_unique = antivenom_unique    \n        \n        self.Kmer_emb_layer = nn.Embedding(\n            num_embeddings=self.K_mer_nunique,\n            embedding_dim=self.K_mer_emb_size,\n        )\n        self.Antivenom_emb = nn.Embedding(\n            num_embeddings=self.antivenom_unique,\n            embedding_dim=self.antivenom_emb_size,\n        )\n    \n        self.Position_start_emb = nn.Embedding(\n            num_embeddings=max_Position_start,\n            embedding_dim=Position_start_emb_size,\n        )\n        self.Features = nn.Linear(\n            in_features=self.antivenom_emb_size + Position_start_emb_size,\n            out_features=128,\n        )\n        \n        self.Lstm_layer_1 = nn.LSTM(\n            input_size=self.K_mer_emb_size,\n            hidden_size=256,\n            num_layers=2,\n            bidirectional=True,\n            batch_first=True,\n        )\n        self.Lstm_layer_2 = nn.GRU(\n            input_size=512,\n            hidden_size=128,\n            num_layers=1,\n            bidirectional=False,\n            batch_first=True,\n        )\n        \n        self.Linear_1 = nn.Linear(\n            in_features=self.Lstm_layer_2.hidden_size + self.Features.out_features,\n            out_features=512,\n        )\n        self.relu_1 = nn.ReLU()\n        self.Linear_2 = nn.Linear(\n            in_features=self.Linear_1.out_features, out_features=256,\n        )\n        self.relu_2 = nn.ReLU()\n        self.Output = nn.Linear(\n            in_features=self.Linear_2.out_features, out_features=1,\n        )\n        \n    def forward(self, inputs):\n        kmer_emb = self.Kmer_emb_layer(inputs[\"K_mer\"])\n        antivenom_emb = self.Antivenom_emb(inputs[\"antivenom\"])\n        position_start_emb = self.Position_start_emb(inputs[\"position_start\"])\n\n        emb_features = torch.cat((antivenom_emb, position_start_emb), axis=1)\n        features = self.Features(emb_features)\n        \n        lstm_1_seq, (lstm_1_h, lstm1_c) = self.Lstm_layer_1(kmer_emb)\n        lstm_2_seq, lstm_2_h = self.Lstm_layer_2(lstm_1_seq)\n\n        lstm_h = torch.squeeze(lstm_2_h)\n        emb = torch.cat((lstm_h, features), axis=1)\n        linear_1 = self.relu_1(self.Linear_1(emb))\n        linear_2 = self.relu_2(self.Linear_2(linear_1))\n        output = self.Output(linear_2)\n        return output\n        \n        ","metadata":{"id":"d828aecc-9bb9-498e-89dd-25fb43482829","execution":{"iopub.status.busy":"2022-03-20T16:07:20.764508Z","iopub.execute_input":"2022-03-20T16:07:20.764829Z","iopub.status.idle":"2022-03-20T16:07:20.784198Z","shell.execute_reply.started":"2022-03-20T16:07:20.764798Z","shell.execute_reply":"2022-03-20T16:07:20.783005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that the model architecture is defined we are goint to instantiate our model. For this we need to calculate `max_Position_start` in order to calculate the size of the embedding layer we will use to encode the start position. The maximum position that the train and test dataset can have is:\n","metadata":{"id":"5Nu4DXk-9jyf"}},{"cell_type":"code","source":"max_Position_start = pd.concat([train_df[[\"Kmer_Position_start\"]], test_df[[\"Kmer_Position_start\"]]]).Kmer_Position_start.max()+1\n\nprint(f\"Max Position_start : {max_Position_start}\")\n","metadata":{"id":"pakRsAlg837A","outputId":"fdaf3b71-bdf2-43b9-d355-401ca9c1d57e","execution":{"iopub.status.busy":"2022-03-20T16:07:21.532889Z","iopub.execute_input":"2022-03-20T16:07:21.533761Z","iopub.status.idle":"2022-03-20T16:07:21.544854Z","shell.execute_reply.started":"2022-03-20T16:07:21.533719Z","shell.execute_reply":"2022-03-20T16:07:21.543665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the model\nWe define a simple training loop\n","metadata":{"id":"Wy_0FRUbJt_W"}},{"cell_type":"code","source":"def train_func(\n    train_data_loader,\n    val_data_loader,\n    model,\n    loss_fn,\n    optimizer,\n    num_epochs,\n    device,\n    early_stopping=5,\n): \n    total_batches = len(train_data_loader)\n    total_batches_val = len(val_data_loader)\n    train_loss = []\n    all_rmse=[]\n    n_iter = 0\n    for epoch in range(num_epochs): \n        tqdm_bar = tqdm(train_data_loader, desc=f\"epoch {epoch}\", position=0) \n        old_val_loss = np.inf\n        wating = 0\n        model.train()\n        for batch_number, (X, y) in enumerate(tqdm_bar):\n            y = y.type(torch.FloatTensor).to(device)\n            X = {k: X[k].to(device) for k in X}\n            \n            optimizer.zero_grad()\n            pred = model(X)\n            loss = loss_fn(pred, y)\n            loss.backward()\n            \n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            \n            loss = loss.item()\n            train_loss.append(loss)\n\n            n_iter += 1\n\n            if batch_number % 25 == 0: \n                tqdm_bar.set_postfix(\n                    {\n                        \"train\": f\"{batch_number}/{total_batches} loss: {loss:.3} epoch loss: {np.mean(train_loss):.3}\",\n                    },\n                )\n\n        val_tqdm_bar = tqdm(\n            val_data_loader, desc=f\"epoch {epoch}\", position=0, leave=True,\n        ) \n        val_loss = []\n        val_rmse=[]\n        model.eval()\n        with torch.no_grad(): \n            for batch_number, (X, y) in enumerate(val_tqdm_bar):\n                y = y.type(torch.FloatTensor).to(device)\n                X = {k: X[k].to(device) for k in X}\n                \n                pred = model(X)\n                val_loss.append(loss_fn(pred, y).item())\n                val_rmse.append(mean_squared_error(pred.cpu(),y.cpu(),squared=False))\n\n\n                if batch_number % 25 == 0: \n                    val_tqdm_bar.set_postfix(\n                        {\n                            \"valid\": f\"{batch_number}/{total_batches_val} val loss: {np.mean(val_loss):.3} val rmse: {np.mean(val_rmse):.3}\"\n                        },\n                    )\n        \n        new_val_loss = np.mean(val_loss)\n\n        if new_val_loss > old_val_loss:\n            wating += wating\n        else:\n            old_val_loss = new_val_loss\n            torch.save(model.state_dict(),f\"best_model_{fold}\") \n\n        if wating > early_stopping:\n            break\n    \n        all_rmse.append(np.mean(val_rmse))\n    return np.mean(all_rmse)","metadata":{"id":"b808e6b1-52bd-4685-a31a-fa665494613d","execution":{"iopub.status.busy":"2022-03-20T16:07:22.517279Z","iopub.execute_input":"2022-03-20T16:07:22.517845Z","iopub.status.idle":"2022-03-20T16:07:22.538728Z","shell.execute_reply.started":"2022-03-20T16:07:22.517789Z","shell.execute_reply":"2022-03-20T16:07:22.537557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR=2e-3\nnum_epochs = 10\nearly_stopping = 5","metadata":{"id":"HvIEWJnmrFK4","execution":{"iopub.status.busy":"2022-03-20T16:19:43.554352Z","iopub.execute_input":"2022-03-20T16:19:43.554648Z","iopub.status.idle":"2022-03-20T16:19:43.559942Z","shell.execute_reply.started":"2022-03-20T16:19:43.554617Z","shell.execute_reply":"2022-03-20T16:19:43.558424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nkfold = KFold(n_splits=5, shuffle=True,random_state=152)\n","metadata":{"id":"B5F_YMzmpSAP","execution":{"iopub.status.busy":"2022-03-20T16:19:48.264649Z","iopub.execute_input":"2022-03-20T16:19:48.265074Z","iopub.status.idle":"2022-03-20T16:19:48.271016Z","shell.execute_reply.started":"2022-03-20T16:19:48.265038Z","shell.execute_reply":"2022-03-20T16:19:48.269935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_rmse_scores = []\nfor fold, (train_ids, test_ids) in enumerate(kfold.split(train_df)):\n  print(f\"#########################  Fold {fold+1}/{kfold.n_splits}  #########################\")\n  train_split_df , val_split_df = train_df.iloc[train_ids,:],train_df.iloc[test_ids,:]\n\n  train_dataset = AntivenomChallengeDataSet(\n    amino_acid_map=amino_acid_map,\n    antivenom_map=antivenom_map,\n    data=train_split_df,\n    is_train=True,\n    label_name=\"Signal\")\n\n  val_dataset = AntivenomChallengeDataSet(\n      amino_acid_map=amino_acid_map,\n      antivenom_map=antivenom_map,\n      data=val_split_df,\n      is_train=True,\n      label_name=\"Signal\")\n  \n  train_data_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=batch_size,\n    shuffle=shuffle,\n    num_workers=num_workers,\n    drop_last=drop_last,)\n\n  val_data_loader = DataLoader(\n      dataset=val_dataset,\n      batch_size=batch_size,\n      shuffle=False,\n      num_workers=num_workers,\n      drop_last=False,)\n  \n  model = SimpleSeqModel(\n    K_mer_emb_size=512,\n    K_mer_nunique=len(amino_acid_map),\n    antivenom_emb_size=64,\n    antivenom_unique=len(antivenom_map),\n    max_Position_start=max_Position_start,\n    Position_start_emb_size=64,)\n\n  loss_fn = nn.MSELoss()\n\n  model = model.to(device)\n\n  optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n  rmse=train_func(\n    train_data_loader=train_data_loader,\n    val_data_loader=val_data_loader,\n    model=model,\n    loss_fn=loss_fn,\n    optimizer=optimizer,\n    num_epochs=num_epochs,\n    device=device,\n    early_stopping=early_stopping)\n  print('RMSE: '+str(rmse))\n  all_rmse_scores.append(rmse)\n","metadata":{"id":"24bULas3poug","outputId":"c469cd4a-8a53-424b-a50b-0e022f579c46","execution":{"iopub.status.busy":"2022-03-20T16:19:48.814863Z","iopub.execute_input":"2022-03-20T16:19:48.815688Z","iopub.status.idle":"2022-03-20T16:46:44.337046Z","shell.execute_reply.started":"2022-03-20T16:19:48.815653Z","shell.execute_reply":"2022-03-20T16:46:44.335129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(all_rmse_scores)","metadata":{"id":"e8d635a3-fa34-4b16-9a76-42dfb736455c","outputId":"8d90d873-5f65-4205-c1d9-a99b069d90eb","execution":{"iopub.status.busy":"2022-03-20T16:46:49.727913Z","iopub.execute_input":"2022-03-20T16:46:49.728259Z","iopub.status.idle":"2022-03-20T16:46:49.735485Z","shell.execute_reply.started":"2022-03-20T16:46:49.728228Z","shell.execute_reply":"2022-03-20T16:46:49.734384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(all_rmse_scores)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T16:47:03.359622Z","iopub.execute_input":"2022-03-20T16:47:03.36008Z","iopub.status.idle":"2022-03-20T16:47:03.367643Z","shell.execute_reply.started":"2022-03-20T16:47:03.360048Z","shell.execute_reply":"2022-03-20T16:47:03.366127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"0.40515295","metadata":{"id":"8kd4aZ1Xq2-7","outputId":"70b79d17-abe9-4676-e986-fcfda1a2d3c5","execution":{"iopub.status.busy":"2022-03-20T15:47:22.442988Z","iopub.execute_input":"2022-03-20T15:47:22.443345Z","iopub.status.idle":"2022-03-20T15:47:22.452236Z","shell.execute_reply.started":"2022-03-20T15:47:22.443311Z","shell.execute_reply":"2022-03-20T15:47:22.451091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sample baseline Submission\nFinally we will prepare a baseline submission to Zindi \n","metadata":{"id":"07JhrgWQJjl3"}},{"cell_type":"code","source":"def predict_test(data_loader, path): \n  all_folds = []\n  for i in range(len(all_rmse_scores)):\n      model = SimpleSeqModel(\n      K_mer_emb_size=512,\n      K_mer_nunique=len(amino_acid_map),\n      antivenom_emb_size=64,\n      antivenom_unique=len(antivenom_map),\n      max_Position_start=max_Position_start,\n      Position_start_emb_size=64,)\n      model.load_state_dict(torch.load(f'best_model_{i}'))\n      model.to(device)\n      model.eval()\n      tqdm_bar = tqdm(data_loader, desc=\"Inference\", position=0, leave=True) \n      total_batches = len(tqdm_bar)\n\n      preds = []\n      with torch.no_grad():\n          for batch_number, X in enumerate(tqdm_bar):\n              X= {k: X[k].to(device) for k in X}\n              pred = model(X)\n              preds.append(pred.cpu().numpy())\n\n          preds = np.concatenate(preds)\n      all_folds.append(preds)\n  return all_folds","metadata":{"id":"NzqYHYOXGh1c","execution":{"iopub.status.busy":"2022-03-20T16:47:28.07224Z","iopub.execute_input":"2022-03-20T16:47:28.07255Z","iopub.status.idle":"2022-03-20T16:47:28.084276Z","shell.execute_reply.started":"2022-03-20T16:47:28.072517Z","shell.execute_reply":"2022-03-20T16:47:28.083181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred = predict_test(test_data_loader,\"model.pth\")","metadata":{"id":"l25s3xDrJc8U","outputId":"9c4960f5-ee9a-4d5e-f1a7-5dd598226e94","execution":{"iopub.status.busy":"2022-03-20T16:47:28.598438Z","iopub.execute_input":"2022-03-20T16:47:28.599222Z","iopub.status.idle":"2022-03-20T16:48:03.388106Z","shell.execute_reply.started":"2022-03-20T16:47:28.599187Z","shell.execute_reply":"2022-03-20T16:48:03.387063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_sum = test_pred[0]\nfor i in range(1,len(test_pred)):\n    out_sum = test_pred[i] + out_sum","metadata":{"id":"LtwUmKpGYSEY","execution":{"iopub.status.busy":"2022-03-20T16:48:05.605694Z","iopub.execute_input":"2022-03-20T16:48:05.606053Z","iopub.status.idle":"2022-03-20T16:48:05.613763Z","shell.execute_reply.started":"2022-03-20T16:48:05.605961Z","shell.execute_reply":"2022-03-20T16:48:05.612708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"((out_sum)/len(test_pred)).reshape((-1))","metadata":{"id":"pD8frBMMalu9","outputId":"38e6ac54-56fa-4290-b8b1-132773a8994f","execution":{"iopub.status.busy":"2022-03-20T16:48:05.994323Z","iopub.execute_input":"2022-03-20T16:48:05.994626Z","iopub.status.idle":"2022-03-20T16:48:06.004476Z","shell.execute_reply.started":"2022-03-20T16:48:05.994592Z","shell.execute_reply":"2022-03-20T16:48:06.003524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission=test_df[[\"ID\"]]\nsample_submission[\"Signal\"] = ((out_sum)/len(test_pred)).reshape((-1))\n","metadata":{"id":"vWXzy2hZGiZq","outputId":"66ae9832-c213-4a9f-a512-4942fd9b842e","execution":{"iopub.status.busy":"2022-03-20T16:48:08.044807Z","iopub.execute_input":"2022-03-20T16:48:08.04545Z","iopub.status.idle":"2022-03-20T16:48:08.171011Z","shell.execute_reply.started":"2022-03-20T16:48:08.045417Z","shell.execute_reply":"2022-03-20T16:48:08.169928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That is it! Now we can upload the sample_submission.csv to Zindi! As a final thing lets look at it. ","metadata":{"id":"BrBsX3OnGRVs"}},{"cell_type":"code","source":"sample_submission['Signal']=sample_submission['Signal'].clip(lower=-1)\nsample_submission.to_csv(\"./sample_submission20.csv\",index=False)","metadata":{"id":"WluOrYzKItCx","execution":{"iopub.status.busy":"2022-03-20T16:48:10.400339Z","iopub.execute_input":"2022-03-20T16:48:10.400732Z","iopub.status.idle":"2022-03-20T16:48:10.81956Z","shell.execute_reply.started":"2022-03-20T16:48:10.400684Z","shell.execute_reply":"2022-03-20T16:48:10.818639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}