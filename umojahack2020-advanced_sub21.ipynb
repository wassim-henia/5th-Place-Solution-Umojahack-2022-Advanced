{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5241c671-48c9-4034-b113-4c285e33b51b",
      "metadata": {
        "id": "5241c671-48c9-4034-b113-4c285e33b51b"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn \n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "SEED_VAL  = 1000\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "def seed_all(SEED):\n",
        "  random.seed(SEED_VAL)\n",
        "  np.random.seed(SEED_VAL)\n",
        "  torch.manual_seed(SEED_VAL)\n",
        "  torch.cuda.manual_seed_all(SEED_VAL)\n",
        "  os.environ['PYTHONHASHSEED'] = str(SEED_VAL)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "seed_all(SEED_VAL)"
      ],
      "metadata": {
        "id": "9bQJ-pUKInAd"
      },
      "id": "9bQJ-pUKInAd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f162f6bb-0dfd-4310-a096-a584aee0f471",
      "metadata": {
        "id": "f162f6bb-0dfd-4310-a096-a584aee0f471"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"https://storage.googleapis.com/umojahack2022/train.csv\")\n",
        "test_df = pd.read_csv(\"https://storage.googleapis.com/umojahack2022/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "wsGP-LGiMH5-",
        "outputId": "e4252e8a-3774-461b-b8b0-03b67ccf8c22"
      },
      "id": "wsGP-LGiMH5-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  ID Toxin_UniprotID  Kmer_Position_start  \\\n",
              "36535  P01405_VINS_Central_Africa_41          P01405                   41   \n",
              "36536  P01405_VINS_Central_Africa_42          P01405                   42   \n",
              "36537  P01405_VINS_Central_Africa_43          P01405                   43   \n",
              "36538  P01405_VINS_Central_Africa_44          P01405                   44   \n",
              "36539  P01405_VINS_Central_Africa_45          P01405                   45   \n",
              "\n",
              "       Kmer_Position_end            Antivenom        Toxin_Kmer        Genus  \\\n",
              "36535                 56  VINS_Central_Africa  PKKEIFRKSIHCCRSD  Dendroaspis   \n",
              "36536                 57  VINS_Central_Africa  KKEIFRKSIHCCRSDK  Dendroaspis   \n",
              "36537                 58  VINS_Central_Africa  KEIFRKSIHCCRSDKC  Dendroaspis   \n",
              "36538                 59  VINS_Central_Africa  EIFRKSIHCCRSDKCN  Dendroaspis   \n",
              "36539                 60  VINS_Central_Africa  IFRKSIHCCRSDKCNE  Dendroaspis   \n",
              "\n",
              "                   Species                ProteinFam          ProteinSubFam  \\\n",
              "36535  Dendroaspis_viridis  Snake_three_finger_toxin  Short_chain_subfamily   \n",
              "36536  Dendroaspis_viridis  Snake_three_finger_toxin  Short_chain_subfamily   \n",
              "36537  Dendroaspis_viridis  Snake_three_finger_toxin  Short_chain_subfamily   \n",
              "36538  Dendroaspis_viridis  Snake_three_finger_toxin  Short_chain_subfamily   \n",
              "36539  Dendroaspis_viridis  Snake_three_finger_toxin  Short_chain_subfamily   \n",
              "\n",
              "                    ProteinSubSubFam  \n",
              "36535  Orphan_group_XI_sub_subfamily  \n",
              "36536  Orphan_group_XI_sub_subfamily  \n",
              "36537  Orphan_group_XI_sub_subfamily  \n",
              "36538  Orphan_group_XI_sub_subfamily  \n",
              "36539  Orphan_group_XI_sub_subfamily  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-631582de-c310-4a6c-84f4-066b8fd201ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Toxin_UniprotID</th>\n",
              "      <th>Kmer_Position_start</th>\n",
              "      <th>Kmer_Position_end</th>\n",
              "      <th>Antivenom</th>\n",
              "      <th>Toxin_Kmer</th>\n",
              "      <th>Genus</th>\n",
              "      <th>Species</th>\n",
              "      <th>ProteinFam</th>\n",
              "      <th>ProteinSubFam</th>\n",
              "      <th>ProteinSubSubFam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36535</th>\n",
              "      <td>P01405_VINS_Central_Africa_41</td>\n",
              "      <td>P01405</td>\n",
              "      <td>41</td>\n",
              "      <td>56</td>\n",
              "      <td>VINS_Central_Africa</td>\n",
              "      <td>PKKEIFRKSIHCCRSD</td>\n",
              "      <td>Dendroaspis</td>\n",
              "      <td>Dendroaspis_viridis</td>\n",
              "      <td>Snake_three_finger_toxin</td>\n",
              "      <td>Short_chain_subfamily</td>\n",
              "      <td>Orphan_group_XI_sub_subfamily</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36536</th>\n",
              "      <td>P01405_VINS_Central_Africa_42</td>\n",
              "      <td>P01405</td>\n",
              "      <td>42</td>\n",
              "      <td>57</td>\n",
              "      <td>VINS_Central_Africa</td>\n",
              "      <td>KKEIFRKSIHCCRSDK</td>\n",
              "      <td>Dendroaspis</td>\n",
              "      <td>Dendroaspis_viridis</td>\n",
              "      <td>Snake_three_finger_toxin</td>\n",
              "      <td>Short_chain_subfamily</td>\n",
              "      <td>Orphan_group_XI_sub_subfamily</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36537</th>\n",
              "      <td>P01405_VINS_Central_Africa_43</td>\n",
              "      <td>P01405</td>\n",
              "      <td>43</td>\n",
              "      <td>58</td>\n",
              "      <td>VINS_Central_Africa</td>\n",
              "      <td>KEIFRKSIHCCRSDKC</td>\n",
              "      <td>Dendroaspis</td>\n",
              "      <td>Dendroaspis_viridis</td>\n",
              "      <td>Snake_three_finger_toxin</td>\n",
              "      <td>Short_chain_subfamily</td>\n",
              "      <td>Orphan_group_XI_sub_subfamily</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36538</th>\n",
              "      <td>P01405_VINS_Central_Africa_44</td>\n",
              "      <td>P01405</td>\n",
              "      <td>44</td>\n",
              "      <td>59</td>\n",
              "      <td>VINS_Central_Africa</td>\n",
              "      <td>EIFRKSIHCCRSDKCN</td>\n",
              "      <td>Dendroaspis</td>\n",
              "      <td>Dendroaspis_viridis</td>\n",
              "      <td>Snake_three_finger_toxin</td>\n",
              "      <td>Short_chain_subfamily</td>\n",
              "      <td>Orphan_group_XI_sub_subfamily</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36539</th>\n",
              "      <td>P01405_VINS_Central_Africa_45</td>\n",
              "      <td>P01405</td>\n",
              "      <td>45</td>\n",
              "      <td>60</td>\n",
              "      <td>VINS_Central_Africa</td>\n",
              "      <td>IFRKSIHCCRSDKCNE</td>\n",
              "      <td>Dendroaspis</td>\n",
              "      <td>Dendroaspis_viridis</td>\n",
              "      <td>Snake_three_finger_toxin</td>\n",
              "      <td>Short_chain_subfamily</td>\n",
              "      <td>Orphan_group_XI_sub_subfamily</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-631582de-c310-4a6c-84f4-066b8fd201ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-631582de-c310-4a6c-84f4-066b8fd201ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-631582de-c310-4a6c-84f4-066b8fd201ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each row in the dataset represents a k-mer (16 amino acid sequence within the toxin) and it has a signal column coming from the high-density peptide microarray experiment. The dataframe has the following columns :\n",
        "```\n",
        "ID: Unique identifier for each row \n",
        "Toxin_UniprotID: Identifier for a specific toxin sequence in the Uniprot Database\n",
        "Kmer_Position_start: The start position in the toxin global sequence of the Kmer_Position_end: The end  position in the toxin global sequence a given k-mer \n",
        "Antivenom: Name of the antivenom tested in the high-density peptide microarray experiment\n",
        "Toxin_Kmer: String of 16 amino acids (16-mer, K=16) from a given toxin sequence\n",
        "Signal: (target) The output of the experiment. A proxy for antivenom activity.\n",
        "Genus: Genus of snake the toxin stems from, e.g. Naja (cobra)\n",
        "Species: Species of snake the toxin originates from e.g. Naja nigricollis (Black-necked spitting cobra)\n",
        "ProteinFam: Toxin protein family, e.g. three finger toxin (3FTx)\n",
        "ProteinSubFam: Toxin sub-family, e.g. cytotoxin (a type of 3FTx)\n",
        "ProteinSubSubFam: Toxin sub-sub-family, e.g. cytotoxin IA (a type of cytotoxin)\n",
        "```\n",
        "\n",
        "We can use any of these colums to train our ML model.\n",
        "\n",
        "For our model, we will use the `Antivenom` and the `Toxin_Kmer` and the `Kmer_Position_start` columns."
      ],
      "metadata": {
        "id": "fS-A-c-KMHnl"
      },
      "id": "fS-A-c-KMHnl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first create our maps, which converts amino acids of the Toxin Kmer sequence and the Antivenom classes to numerical values"
      ],
      "metadata": {
        "id": "eZ0ooJ5vLzxc"
      },
      "id": "eZ0ooJ5vLzxc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5280d7c6-57df-4822-af33-e24ca6b13f2e",
      "metadata": {
        "id": "5280d7c6-57df-4822-af33-e24ca6b13f2e"
      },
      "outputs": [],
      "source": [
        "def get_seq_column_map(train, test, col):\n",
        "    sequences = []\n",
        "    for seq in train[col]:\n",
        "        sequences.extend(list(seq))\n",
        "    for seq in test[col]:\n",
        "        sequences.extend(list(seq))\n",
        "    unique = np.unique(sequences)\n",
        "    return {k: v for k, v in zip(unique, range(len(unique)))}\n",
        "\n",
        "def get_column_map(train, test, col):\n",
        "    sequences = []\n",
        "    unique_values = pd.concat([train[col], test[col]]).unique().tolist()\n",
        "    return {k: v for k, v in zip(unique_values, range(len(unique_values)))}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "amino_acid_map = get_seq_column_map(train_df, test_df, \"Toxin_Kmer\")\n",
        "print(\"unique amino acid map\",len(amino_acid_map))\n",
        "\n",
        "antivenom_map = get_column_map(train_df, test_df, \"Antivenom\")\n",
        "print(\"unique Antivenom map\", len(antivenom_map))\n",
        "\n",
        "Species_map = get_column_map(train_df, test_df, \"Species\")\n",
        "print(\"unique Species map\", len(Species_map))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTTjPAPN4b5c",
        "outputId": "d57d11f7-59a2-41ef-d339-b9708152cd83"
      },
      "id": "jTTjPAPN4b5c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique amino acid map 20\n",
            "unique Antivenom map 8\n",
            "unique Species map 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will split the data into a training and a validation set"
      ],
      "metadata": {
        "id": "YSDgPC4YNm1w"
      },
      "id": "YSDgPC4YNm1w"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We look at the GPU provided by Colab"
      ],
      "metadata": {
        "id": "49jlxU1QN4s3"
      },
      "id": "49jlxU1QN4s3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "810517e6-008a-485c-8f6d-74db2cfb1770",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "810517e6-008a-485c-8f6d-74db2cfb1770",
        "outputId": "078db37e-ec38-4e93-f143-b0b84b585768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device : cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"device : {device}\")\n",
        "torch.cuda.get_device_name()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We convert our data into a torch `Dataset`.\n",
        "All datasets that represent a map from keys to data samples should subclass\n",
        "`Dataset`. All subclasses should overwrite `__getitem__`, supporting fetching a data sample for a given key:"
      ],
      "metadata": {
        "id": "y4HuvmEUODzZ"
      },
      "id": "y4HuvmEUODzZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c38ed84-d4a2-4045-99b6-3165e4b7ea76",
      "metadata": {
        "id": "5c38ed84-d4a2-4045-99b6-3165e4b7ea76"
      },
      "outputs": [],
      "source": [
        "class AntivenomChallengeDataSet(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        amino_acid_map,\n",
        "        antivenom_map,\n",
        "        Species_map,\n",
        "        data,\n",
        "        is_train,\n",
        "        label_name=None,\n",
        "      ):\n",
        "        self.amino_acid_map = amino_acid_map\n",
        "        self.antivenom_map = antivenom_map\n",
        "        self.Species_map=Species_map\n",
        "        self.data = data\n",
        "        self.is_train = is_train\n",
        "        self.label_name = label_name\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) \n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        kmer_seq = torch.as_tensor([self.amino_acid_map[e] for e in list(row[\"Toxin_Kmer\"])])\n",
        "        antivenom = torch.as_tensor(self.antivenom_map[row[\"Antivenom\"]])\n",
        "        Species=torch.as_tensor(self.Species_map[row[\"Species\"]])\n",
        "        position_start = torch.as_tensor(row[\"Kmer_Position_start\"])\n",
        "        position_end = torch.as_tensor(row[\"Kmer_Position_end\"])\n",
        "        \n",
        "        inputs = {\n",
        "            \"K_mer\": kmer_seq,\n",
        "            \"antivenom\": antivenom,\n",
        "            \"Species\":Species,\n",
        "            \"position_start\": position_start,\n",
        "            \"position_end\": position_end,\n",
        "        }\n",
        "\n",
        "        if self.is_train: \n",
        "            return inputs, torch.as_tensor([row[self.label_name]])\n",
        "        return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04ee359a-ab9f-422e-ae71-50685acd0c44",
      "metadata": {
        "id": "04ee359a-ab9f-422e-ae71-50685acd0c44"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_dataset = AntivenomChallengeDataSet(\n",
        "    amino_acid_map=amino_acid_map,\n",
        "    antivenom_map=antivenom_map,\n",
        "    Species_map = Species_map,\n",
        "    data=test_df,\n",
        "    is_train=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cc84cdb-dfc7-4910-a83f-2d1a52ddd5e4",
      "metadata": {
        "id": "3cc84cdb-dfc7-4910-a83f-2d1a52ddd5e4"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "num_workers = 0\n",
        "shuffle = True\n",
        "drop_last = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create our PyTorch data loaders. These combine a dataset and a sampler, and provide an iterable over the given dataset."
      ],
      "metadata": {
        "id": "sQ15jMHhO3zh"
      },
      "id": "sQ15jMHhO3zh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0e3ab3d-540b-4a84-ac68-61376aefb299",
      "metadata": {
        "id": "c0e3ab3d-540b-4a84-ac68-61376aefb299"
      },
      "outputs": [],
      "source": [
        "test_data_loader= DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model\n",
        "For this example we will build an LSTM architeture. It is your task to come up with more performant architectures to improve the scores."
      ],
      "metadata": {
        "id": "4lXf0OdpP_zh"
      },
      "id": "4lXf0OdpP_zh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d828aecc-9bb9-498e-89dd-25fb43482829",
      "metadata": {
        "id": "d828aecc-9bb9-498e-89dd-25fb43482829"
      },
      "outputs": [],
      "source": [
        "class SimpleSeqModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        K_mer_emb_size,\n",
        "        K_mer_nunique,\n",
        "        antivenom_emb_size,\n",
        "        antivenom_unique,\n",
        "        Species_emb_size,\n",
        "        Species_unique,\n",
        "        max_Position_start,\n",
        "        Position_start_emb_size,\n",
        "    ): \n",
        "        super().__init__()\n",
        "        self.K_mer_emb_size = K_mer_emb_size        \n",
        "        self.K_mer_nunique = K_mer_nunique                \n",
        "        self.antivenom_emb_size = antivenom_emb_size  \n",
        "        self.antivenom_unique = antivenom_unique    \n",
        "        self.Species_emb_size = Species_emb_size  \n",
        "        self.Species_unique = Species_unique \n",
        "\n",
        "        self.Kmer_emb_layer = nn.Embedding(\n",
        "            num_embeddings=self.K_mer_nunique,\n",
        "            embedding_dim=self.K_mer_emb_size,\n",
        "        )\n",
        "        self.Antivenom_emb = nn.Embedding(\n",
        "            num_embeddings=self.antivenom_unique,\n",
        "            embedding_dim=self.antivenom_emb_size,\n",
        "        )\n",
        "\n",
        "        self.Species_emb = nn.Embedding(\n",
        "            num_embeddings=self.Species_unique,\n",
        "            embedding_dim=self.Species_emb_size,\n",
        "        )\n",
        "    \n",
        "        self.Position_start_emb = nn.Embedding(\n",
        "            num_embeddings=max_Position_start,\n",
        "            embedding_dim=Position_start_emb_size,\n",
        "        )\n",
        "        self.Features = nn.Linear(\n",
        "            in_features=self.antivenom_emb_size +self.Species_emb_size + Position_start_emb_size,\n",
        "            out_features=128,\n",
        "        )\n",
        "        \n",
        "        self.Lstm_layer_1 = nn.LSTM(\n",
        "            input_size=self.K_mer_emb_size,\n",
        "            hidden_size=256,\n",
        "            num_layers=1,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.Lstm_layer_2 = nn.GRU(\n",
        "            input_size=512,\n",
        "            hidden_size=256,\n",
        "            num_layers=1,\n",
        "            bidirectional=False,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.Lstm_layer_3 = nn.GRU(\n",
        "            input_size=512,\n",
        "            hidden_size=128,\n",
        "            num_layers=1,\n",
        "            bidirectional=False,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        \n",
        "        self.Linear_1 = nn.Linear(\n",
        "            in_features=self.Lstm_layer_2.hidden_size + self.Features.out_features,\n",
        "            out_features=512,\n",
        "        )\n",
        "        self.relu_1 = nn.ReLU()\n",
        "        self.Linear_2 = nn.Linear(\n",
        "            in_features=self.Linear_1.out_features, out_features=256,\n",
        "        )\n",
        "        self.relu_2 = nn.ReLU()\n",
        "        self.Output = nn.Linear(\n",
        "            in_features=self.Linear_2.out_features, out_features=1,\n",
        "        )\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        kmer_emb = self.Kmer_emb_layer(inputs[\"K_mer\"])\n",
        "        antivenom_emb = self.Antivenom_emb(inputs[\"antivenom\"])\n",
        "        Species_emb = self.Species_emb(inputs[\"Species\"])\n",
        "        position_start_emb = self.Position_start_emb(inputs[\"position_start\"])\n",
        "\n",
        "        emb_features = torch.cat((antivenom_emb, position_start_emb,Species_emb), axis=1)\n",
        "        features = self.Features(emb_features)\n",
        "        \n",
        "        lstm_1_seq, lstm_1_h = self.Lstm_layer_1(kmer_emb)\n",
        "        lstm_2_seq, lstm_2_h = self.Lstm_layer_2(lstm_1_seq)\n",
        "        #lstm_3_seq, lstm_3_h = self.Lstm_layer_3(lstm_2_seq)\n",
        "\n",
        "        lstm_h = torch.squeeze(lstm_2_h)\n",
        "        emb = torch.cat((lstm_h, features), axis=1)\n",
        "        linear_1 = self.relu_1(self.Linear_1(emb))\n",
        "        linear_2 = self.relu_2(self.Linear_2(linear_1))\n",
        "        output = self.Output(linear_2)\n",
        "        return output\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the model architecture is defined we are goint to instantiate our model. For this we need to calculate `max_Position_start` in order to calculate the size of the embedding layer we will use to encode the start position. The maximum position that the train and test dataset can have is:\n"
      ],
      "metadata": {
        "id": "5Nu4DXk-9jyf"
      },
      "id": "5Nu4DXk-9jyf"
    },
    {
      "cell_type": "code",
      "source": [
        "max_Position_start = pd.concat([train_df[[\"Kmer_Position_start\"]], test_df[[\"Kmer_Position_start\"]]]).Kmer_Position_start.max()+1\n",
        "\n",
        "print(f\"Max Position_start : {max_Position_start}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pakRsAlg837A",
        "outputId": "55a8e3b1-be96-47f3-ba84-4de78d307604"
      },
      "id": "pakRsAlg837A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Position_start : 596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_Position_end = pd.concat([train_df[[\"Kmer_Position_end\"]], test_df[[\"Kmer_Position_end\"]]]).Kmer_Position_end.max()+1\n",
        "\n",
        "print(f\"Max Position_start : {max_Position_end}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w5ynrzL0POR",
        "outputId": "a4777105-1195-41e2-b75f-4c9c6a281bc7"
      },
      "id": "5w5ynrzL0POR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Position_start : 611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model\n",
        "We define a simple training loop\n"
      ],
      "metadata": {
        "id": "Wy_0FRUbJt_W"
      },
      "id": "Wy_0FRUbJt_W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b808e6b1-52bd-4685-a31a-fa665494613d",
      "metadata": {
        "id": "b808e6b1-52bd-4685-a31a-fa665494613d"
      },
      "outputs": [],
      "source": [
        "def train_func(\n",
        "    train_data_loader,\n",
        "    val_data_loader,\n",
        "    model,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    num_epochs,\n",
        "    device,\n",
        "    early_stopping=5,\n",
        "): \n",
        "    total_batches = len(train_data_loader)\n",
        "    total_batches_val = len(val_data_loader)\n",
        "    train_loss = []\n",
        "    all_rmse=[]\n",
        "    n_iter = 0\n",
        "    for epoch in range(num_epochs): \n",
        "        tqdm_bar = tqdm(train_data_loader, desc=f\"epoch {epoch}\", position=0) \n",
        "        old_val_loss = np.inf\n",
        "        wating = 0\n",
        "        model.train()\n",
        "        for batch_number, (X, y) in enumerate(tqdm_bar):\n",
        "            y = y.type(torch.FloatTensor).to(device)\n",
        "            X = {k: X[k].to(device) for k in X}\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            \n",
        "            loss = loss.item()\n",
        "            train_loss.append(loss)\n",
        "\n",
        "            n_iter += 1\n",
        "\n",
        "            if batch_number % 25 == 0: \n",
        "                tqdm_bar.set_postfix(\n",
        "                    {\n",
        "                        \"train\": f\"{batch_number}/{total_batches} loss: {loss:.3} epoch loss: {np.mean(train_loss):.3}\",\n",
        "                    },\n",
        "                )\n",
        "\n",
        "        val_tqdm_bar = tqdm(\n",
        "            val_data_loader, desc=f\"epoch {epoch}\", position=0, leave=True,\n",
        "        ) \n",
        "        val_loss = []\n",
        "        val_rmse=[]\n",
        "        model.eval()\n",
        "        with torch.no_grad(): \n",
        "            for batch_number, (X, y) in enumerate(val_tqdm_bar):\n",
        "                y = y.type(torch.FloatTensor).to(device)\n",
        "                X = {k: X[k].to(device) for k in X}\n",
        "                \n",
        "                pred = model(X)\n",
        "                val_loss.append(loss_fn(pred, y).item())\n",
        "                val_rmse.append(mean_squared_error(pred.cpu(),y.cpu(),squared=False))\n",
        "\n",
        "\n",
        "                if batch_number % 25 == 0: \n",
        "                    val_tqdm_bar.set_postfix(\n",
        "                        {\n",
        "                            \"valid\": f\"{batch_number}/{total_batches_val} val loss: {np.mean(val_loss):.3} val rmse: {np.mean(val_rmse):.3}\"\n",
        "                        },\n",
        "                    )\n",
        "        \n",
        "        new_val_loss = np.mean(val_loss)\n",
        "\n",
        "        if new_val_loss > old_val_loss:\n",
        "            wating += wating\n",
        "        else:\n",
        "            old_val_loss = new_val_loss\n",
        "            torch.save(model.state_dict(),f\"best_model_{fold}\") \n",
        "\n",
        "        if wating > early_stopping:\n",
        "            break\n",
        "    \n",
        "        all_rmse.append(np.mean(val_rmse))\n",
        "    return np.mean(all_rmse)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR=1e-3\n",
        "num_epochs = 10\n",
        "early_stopping = 5"
      ],
      "metadata": {
        "id": "HvIEWJnmrFK4"
      },
      "id": "HvIEWJnmrFK4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10, shuffle=True,random_state=152)\n"
      ],
      "metadata": {
        "id": "B5F_YMzmpSAP"
      },
      "id": "B5F_YMzmpSAP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_rmse_scores = []\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(train_df)):\n",
        "  print(f\"#########################  Fold {fold+1}/{kfold.n_splits}  #########################\")\n",
        "  train_split_df , val_split_df = train_df.iloc[train_ids,:],train_df.iloc[test_ids,:]\n",
        "\n",
        "  train_dataset = AntivenomChallengeDataSet(\n",
        "    amino_acid_map=amino_acid_map,\n",
        "    antivenom_map=antivenom_map,\n",
        "    Species_map=Species_map,\n",
        "    data=train_split_df,\n",
        "    is_train=True,\n",
        "    label_name=\"Signal\")\n",
        "\n",
        "  val_dataset = AntivenomChallengeDataSet(\n",
        "      amino_acid_map=amino_acid_map,\n",
        "      antivenom_map=antivenom_map,\n",
        "      Species_map=Species_map,\n",
        "      data=val_split_df,\n",
        "      is_train=True,\n",
        "      label_name=\"Signal\")\n",
        "  \n",
        "  train_data_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=shuffle,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=drop_last,)\n",
        "\n",
        "  val_data_loader = DataLoader(\n",
        "      dataset=val_dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      drop_last=False,)\n",
        "  \n",
        "  model = SimpleSeqModel(\n",
        "    K_mer_emb_size=512,\n",
        "    K_mer_nunique=len(amino_acid_map),\n",
        "    antivenom_emb_size=64,\n",
        "    antivenom_unique=len(antivenom_map),\n",
        "    Species_emb_size=64,\n",
        "    Species_unique=len(Species_map),\n",
        "    max_Position_start=max_Position_start,\n",
        "    Position_start_emb_size=64,\n",
        "    )\n",
        "\n",
        "  loss_fn = nn.MSELoss()\n",
        "\n",
        "  model = model.to(device)\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "  rmse=train_func(\n",
        "    train_data_loader=train_data_loader,\n",
        "    val_data_loader=val_data_loader,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=num_epochs,\n",
        "    device=device,\n",
        "    early_stopping=early_stopping)\n",
        "  print('RMSE: '+str(rmse))\n",
        "  all_rmse_scores.append(rmse)\n"
      ],
      "metadata": {
        "id": "24bULas3poug"
      },
      "id": "24bULas3poug",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8d635a3-fa34-4b16-9a76-42dfb736455c",
      "metadata": {
        "id": "e8d635a3-fa34-4b16-9a76-42dfb736455c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9cb8514-d65e-4ebe-cd7f-b51c5e9fb8ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40799496"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "  np.mean(all_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.43105435\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kd4aZ1Xq2-7",
        "outputId": "e7d931dd-ed61-4242-8534-4e982bff7962"
      },
      "id": "8kd4aZ1Xq2-7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43105435"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample baseline Submission\n",
        "Finally we will prepare a baseline submission to Zindi \n"
      ],
      "metadata": {
        "id": "07JhrgWQJjl3"
      },
      "id": "07JhrgWQJjl3"
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_test(data_loader, path): \n",
        "  all_folds = []\n",
        "  for i in range(len(all_rmse_scores)):\n",
        "      model = SimpleSeqModel(\n",
        "      K_mer_emb_size=512,\n",
        "      K_mer_nunique=len(amino_acid_map),\n",
        "      antivenom_emb_size=64,\n",
        "      antivenom_unique=len(antivenom_map),\n",
        "      Species_emb_size=64,\n",
        "      Species_unique=len(Species_map),\n",
        "      max_Position_start=max_Position_start,\n",
        "      Position_start_emb_size=64,)\n",
        "\n",
        "      model.load_state_dict(torch.load(f'best_model_{i}'))\n",
        "      model.to(device)\n",
        "      model.eval()\n",
        "      tqdm_bar = tqdm(data_loader, desc=\"Inference\", position=0, leave=True) \n",
        "      total_batches = len(tqdm_bar)\n",
        "\n",
        "      preds = []\n",
        "      with torch.no_grad():\n",
        "          for batch_number, X in enumerate(tqdm_bar):\n",
        "              X= {k: X[k].to(device) for k in X}\n",
        "              pred = model(X)\n",
        "              preds.append(pred.cpu().numpy())\n",
        "\n",
        "          preds = np.concatenate(preds)\n",
        "      all_folds.append(preds)\n",
        "  return all_folds"
      ],
      "metadata": {
        "id": "NzqYHYOXGh1c"
      },
      "id": "NzqYHYOXGh1c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = predict_test(test_data_loader,\"model.pth\")"
      ],
      "metadata": {
        "id": "l25s3xDrJc8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fdff70a-d544-4a9b-d7c8-b14cf5647c91"
      },
      "id": "l25s3xDrJc8U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 100%|██████████| 286/286 [00:19<00:00, 14.71it/s]\n",
            "Inference: 100%|██████████| 286/286 [00:12<00:00, 22.39it/s]\n",
            "Inference: 100%|██████████| 286/286 [00:12<00:00, 22.10it/s]\n",
            "Inference: 100%|██████████| 286/286 [00:12<00:00, 22.53it/s]\n",
            "Inference: 100%|██████████| 286/286 [00:13<00:00, 21.74it/s]\n",
            "Inference: 100%|██████████| 286/286 [00:12<00:00, 22.33it/s]\n",
            "Inference: 100%|██████████| 286/286 [00:13<00:00, 21.27it/s]\n",
            "Inference: 100%|██████████| 286/286 [00:12<00:00, 22.26it/s]\n",
            "Inference: 100%|██████████| 286/286 [00:12<00:00, 22.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_sum = test_pred[0]\n",
        "for i in range(1,len(test_pred)):\n",
        "    out_sum = test_pred[i] + out_sum"
      ],
      "metadata": {
        "id": "LtwUmKpGYSEY"
      },
      "id": "LtwUmKpGYSEY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "((out_sum)/len(test_pred)).reshape((-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD8frBMMalu9",
        "outputId": "03fe8cee-b6c1-4159-ce59-12f9539fb1c8"
      },
      "id": "pD8frBMMalu9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.70908093, -0.52697235, -0.54813975, ...,  0.1241264 ,\n",
              "        0.47769532,  0.4275658 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission=test_df[[\"ID\"]]\n",
        "sample_submission[\"Signal\"] = ((out_sum)/len(test_pred)).reshape((-1))\n",
        "sample_submission['Signal']=sample_submission['Signal'].clip(lower=-1)\n",
        "sample_submission.to_csv(\"./sample_submission21.csv\",index=False)"
      ],
      "metadata": {
        "id": "vWXzy2hZGiZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff595dc-6ed2-49fe-c9c2-ab6d64b4e6fa"
      },
      "id": "vWXzy2hZGiZq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Copy of Instadeep_StarterNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}